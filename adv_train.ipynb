{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Adversarial training using FSGM\n",
    "Models MobileNetV2, ResNet18, EfficientNet-B0, DenseNet121\n",
    "'''\n",
    "\n",
    "import torch \n",
    "from datasets import load_from_disk\n",
    "\n",
    "DATA_PATH = \"~/Datasets/cv_project/resized_oxford_pets_22\"\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_WORKERS = 4\n",
    "# FSGM perturbation size\n",
    "EPSILON = 0.01\n",
    "\n",
    "'''\n",
    "Dataset class imports whole dataset, in any format\n",
    "    torch.utils.data.Dataset\n",
    "    methdo __len__() to discover size, __getitem__() to get instances by key (default key is integer)\n",
    "    main parameters: dataset, batch size, shuffle\n",
    "DataLoader class pulls samples from dataset, where you specify batch size\n",
    "'''\n",
    "\n",
    "# Load datasets \n",
    "\n",
    "ds = load_from_disk(DATA_PATH) # Visualize at https://huggingface.co/datasets/visual-layer/oxford-iiit-pet-vl-enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare data...\n",
      "Transforms defined!\n",
      "Applying transforms...\n",
      "Pulling batches...\n",
      "train size: 3638, test size: 3626\n",
      "torch.Size([16, 3, 224, 224]) torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "\n",
    "from datasets import ClassLabel\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms \n",
    "import numpy as np\n",
    "\n",
    "img_col   = 'image'\n",
    "label_col = 'label_breed'\n",
    "\n",
    "# Build a map from string labels to int\n",
    "labels = ds['train'].unique(label_col)\n",
    "labels.sort()                        \n",
    "label2int = {v: i for i, v in enumerate(labels)}\n",
    "\n",
    "print('Prepare data...')\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],\n",
    "                         [0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "print('Transforms defined!')\n",
    "print('Applying transforms...')\n",
    "\n",
    "# Apply transforms \n",
    "def preprocess(example):\n",
    "    img = np.array(example[img_col], dtype=np.uint8)\n",
    "    example['pixel_values'] = transform(img)\n",
    "    example['labels'] = torch.tensor(label2int[example[label_col]], dtype=torch.long)\n",
    "    return example\n",
    "\n",
    "ds = ds.map(preprocess, remove_columns=[img_col, label_col])\n",
    "ds.set_format(type='torch', columns=['pixel_values', 'labels'])\n",
    "\n",
    "print('Pulling batches...')\n",
    "\n",
    "# Pull batches\n",
    "train_loader = DataLoader(ds['train'], batch_size=BATCH_SIZE, shuffle=True,  num_workers=NUM_WORKERS)\n",
    "test_loader  = DataLoader(ds['test'],  batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "\n",
    "# Sanity check\n",
    "print(f\"train size: {len(ds['train'])}, test size: {len(ds['test'])}\")\n",
    "batch = next(iter(train_loader))\n",
    "print(batch['pixel_values'].shape, batch['labels'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device before loading models and optimizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Models \n",
    "\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "import timm\n",
    "\n",
    "num_classes = len(label2int)\n",
    "\n",
    "# MobileNetV2\n",
    "mobilenet = models.mobilenet_v2(weights=True)\n",
    "mobilenet.classifier[1] = nn.Linear(\n",
    "    mobilenet.classifier[1].in_features, num_classes)\n",
    "mobilenet = mobilenet.to(device)\n",
    "\n",
    "# ResNet18 (standard fc)\n",
    "resnet = models.resnet18(weights=True)\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, num_classes)\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "# EfficientNet-B0\n",
    "effnet = models.efficientnet_b0(weights=True)\n",
    "in_feats = effnet.classifier[1].in_features\n",
    "effnet.classifier[1] = nn.Linear(in_feats, num_classes)\n",
    "effnet = effnet.to(device)\n",
    "\n",
    "# DenseNet121\n",
    "densenet = timm.create_model('densenet121', pretrained=True)\n",
    "in_feats = densenet.classifier.in_features\n",
    "densenet.classifier = nn.Linear(in_feats, num_classes)\n",
    "densenet = densenet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adversarial training loop (FSGM) \n",
    "# Reference: https://arxiv.org/pdf/1412.6572\n",
    "\n",
    "'''\n",
    "Adversarial training is about becoming aware of the models' security and robustness\n",
    "The overarching goal of an adversary is to add the least amount of perturbation to the input data to cause the desired misclassification, fooling the model\n",
    "\n",
    "Fast Gradient Sign Attack (FSGM) is a white-box attack, i.e. the attacker has full knowledge and access to the model (architecture, inputs, outputs, and weights)\n",
    "which doesn't care of which label the model will give, as long as it misclassifies\n",
    "Idea: it uses gradients to perturbe inputs and fool the model\n",
    "How it works: at each batch iteration\n",
    " - take an input x and compute gradient of loss wrt x, fixing parameters at current value ('E'ven early in training, neural networks exhibit locally linear behavior — especially in high dimensions.' hence gradient direction is already the \"right\" one)\n",
    " - observe sign of gradient \n",
    " - perturb input in THAT direction (loss will be higher): x' <- x + e*grad\n",
    " - train model half with x and half x'\n",
    " - for a big enough perturbation e, the model will misclassify x' \n",
    " > result: regularized and more robust model!\n",
    "'''\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "# Normalization stats (same as in transforms)\n",
    "means = torch.tensor([0.485, 0.456, 0.406], device=device).view(1, 3, 1, 1)\n",
    "stds  = torch.tensor([0.229, 0.224, 0.225], device=device).view(1, 3, 1, 1)\n",
    "\n",
    "# Precompute the valid min/max for each channel in *normalized* space\n",
    "min_val = (0.0 - means) / stds\n",
    "max_val = (1.0 - means) / stds\n",
    "\n",
    "def fgsm_attack(model, loss_f, x, y, epsilon):\n",
    "    \"\"\"\n",
    "    Given a batch (x, y), returns adversarial examples x_adv\n",
    "    via one-step FGSM under L_inf constraint epsilon.\n",
    "    it needs all the model, loss and inputs parameters as it does a backprop step altogether!\n",
    "    \"\"\"\n",
    "    # Make a copy of x that we can take gradients wrt\n",
    "    x_copy = x.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    # Fw and Bw pass to compute graident of the loss wrt input x \n",
    "    outputs = model(x_copy) \n",
    "    loss = loss_f(outputs, y)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Perturbe x!\n",
    "    sign_grad = x_copy.grad.sign()\n",
    "    x_adv = x_copy + epsilon * sign_grad\n",
    "    \n",
    "    # if your inputs are normalized, you may want to clamp in normalized space\n",
    "    # here we assume pixel range [0, 1]:\n",
    "    x_adv = torch.max(torch.min(x_adv, max_val), min_val)\n",
    "    \n",
    "    return x_adv.detach()\n",
    "\n",
    "# Train on adversarial examples \n",
    "def train_model_adv(model, loader, epochs=NUM_EPOCHS, epsilon=EPSILON):\n",
    "    model.train()\n",
    "    loss_f = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        total_loss = 0.0\n",
    "        for batch in loader:\n",
    "            inputs = batch[\"pixel_values\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "                        \n",
    "            # Compute perturbed inputs!\n",
    "            inputs_adv = fgsm_attack(model, loss_f, inputs, labels, epsilon)\n",
    "\n",
    "            # Train half on perturbed half on clean (concretely averaging losses is the same as combining the dataset)\n",
    "            outputs_clean = model(inputs)\n",
    "            outputs_adv = model(inputs_adv)\n",
    "            loss_clean = loss_f(outputs_clean, labels)\n",
    "            loss_adv = loss_f(outputs_adv, labels)\n",
    "            loss = 0.5 * loss_clean + 0.5 * loss_adv\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        avg_loss = total_loss / len(loader.dataset)\n",
    "        print(f\"Epoch {epoch}/{epochs} - Adv Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adv. training densenet...\n",
      "Epoch 1/10 - Adv Loss: 2.6618\n",
      "Epoch 2/10 - Adv Loss: 1.1144\n",
      "Epoch 3/10 - Adv Loss: 0.6475\n",
      "Epoch 4/10 - Adv Loss: 0.4277\n",
      "Epoch 5/10 - Adv Loss: 0.2886\n",
      "Epoch 6/10 - Adv Loss: 0.2125\n",
      "Epoch 7/10 - Adv Loss: 0.1460\n",
      "Epoch 8/10 - Adv Loss: 0.1008\n",
      "Epoch 9/10 - Adv Loss: 0.0927\n",
      "Epoch 10/10 - Adv Loss: 0.0680\n"
     ]
    }
   ],
   "source": [
    "# Adversarially train models\n",
    "\n",
    "import gc\n",
    "\n",
    "for name, model in [\n",
    "    # (\"mobilenet\", mobilenet), \n",
    "    # (\"resnet\", resnet), \n",
    "    # (\"effnet\", effnet),\n",
    "    (\"densenet\", densenet)\n",
    "]:\n",
    "    print(f\"Adv. training {name}...\")\n",
    "    train_model_adv(model, train_loader)\n",
    "    torch.save(model.state_dict(), f\"trained_models/{name}_adv.pt\")\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing loop\n",
    "\n",
    "# Define top-k accuracy\n",
    "def top_k_accuracy(outputs, labels, k=5):\n",
    "    _, topk_preds = outputs.topk(k, dim=1)\n",
    "    correct = topk_preds.eq(labels.view(-1, 1).expand_as(topk_preds))\n",
    "    return correct.any(dim=1).float().mean().item()\n",
    "\n",
    "# Test models\n",
    "def test_model(model, loader, k=5):\n",
    "    model.eval()\n",
    "    correct1 = 0\n",
    "    correct_k_total = 0.0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            inputs = batch['pixel_values'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(inputs)\n",
    "            # Top-1\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct1 += (preds == labels).sum().item()\n",
    "            # Top-k\n",
    "            batch_k_acc = top_k_accuracy(outputs, labels, k)\n",
    "            correct_k_total += batch_k_acc * labels.size(0)\n",
    "            total += labels.size(0)\n",
    "    print(f\"Top-1 Accuracy: {correct1 / total:.4f}\")\n",
    "    print(f\"Top-{k} Accuracy: {correct_k_total / total:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing adv. densenet...\n",
      "Top-1 Accuracy: 0.8530\n",
      "Top-5 Accuracy: 0.9823\n"
     ]
    }
   ],
   "source": [
    "# Adversarially test models\n",
    "\n",
    "# Re-load models as before, with weights=False to avoid waste because I load my own weights later, by name\n",
    "def get_model(name):\n",
    "    if name == \"mobilenet\":\n",
    "        model = models.mobilenet_v2(weights=None)\n",
    "        model.classifier[1] = nn.Linear(\n",
    "            model.classifier[1].in_features, num_classes)\n",
    "    elif name == \"resnet\":\n",
    "        model = models.resnet18(weights=None)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    elif name == \"effnet\":\n",
    "        model = models.efficientnet_b0(weights=None)\n",
    "        in_feats = model.classifier[1].in_features\n",
    "        model.classifier[1] = nn.Linear(in_feats, num_classes)\n",
    "    elif name ==\"densenet\":\n",
    "        model = timm.create_model('densenet121', pretrained=False)\n",
    "        in_feats = model.classifier.in_features\n",
    "        model.classifier = nn.Linear(in_feats, num_classes)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {name}\")\n",
    "    return model\n",
    "\n",
    "for name in [\n",
    "    # \"mobilenet\", \n",
    "    # \"resnet\", \n",
    "    # \"effnet\",\n",
    "    \"densenet\"\n",
    "]:\n",
    "    print(f\"\\nTesting adv. {name}...\")\n",
    "\n",
    "    # Save model to device\n",
    "    model = get_model(name).to(device)\n",
    "    # Load weights computed with training\n",
    "    model.load_state_dict(torch.load(f\"trained_models/{name}_adv.pt\"))\n",
    "    # Test\n",
    "    model.eval()\n",
    "    test_model(model, test_loader)\n",
    "\n",
    "    # Cleanup memory between models\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_venv",
   "language": "python",
   "name": "cv_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
